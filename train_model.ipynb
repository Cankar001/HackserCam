{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model generation (using support vector)\n",
    "heavily inspired by: https://github.com/aditi-govindu/Image-Classsification-using-sklearn/blob/main/Image_Classification_using_SVM.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install scikit-image\n",
    "%pip install scikit-learn\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../Kamera_Image_res/z3_classified/\"\n",
    "MODEL_NAME = \"model\"\n",
    "RANDOM_SEED = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(DATA_DIR)\n",
    "\n",
    "features = [\"clean\", \"dirty\"]\n",
    "images = []\n",
    "flat = []\n",
    "target = []\n",
    "\n",
    "for feature in features:\n",
    "    feature_idx = features.index(feature)\n",
    "    path = DATA_DIR / feature\n",
    "    for img in path.glob(\"./*.jpg\"):\n",
    "        img_arr = imread(img)\n",
    "        img_resize = resize(img_arr, (150,150,3))\n",
    "\n",
    "        flat.append(img_resize.flatten())\n",
    "        images.append(img_resize)\n",
    "        target.append(feature_idx)\n",
    "\n",
    "flat = np.array(flat)\n",
    "images = np.array(flat)\n",
    "target = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(flat)\n",
    "df[\"Target\"] = target\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.iloc[:,:-1].values\n",
    "y = target\n",
    "\n",
    "print(\"Input data dimensions:\",x.shape)\n",
    "print(\"Output data dimensions:\",y.shape)\n",
    "\n",
    "# train / test split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,shuffle=True,test_size = 0.3,random_state=101,stratify=y)\n",
    "print(\"# input training data:\",x_train.shape)\n",
    "print(\"# input testing data:\",x_test.shape)\n",
    "print(\"# output training data:\",y_train.shape)\n",
    "print(\"# output testing data:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Check if testing and training data are divided in equal proportions\n",
    "print(\"Labels\\t\\t   Image index considered\")\n",
    "print(np.unique(y_train,return_counts=True))\n",
    "print(np.unique(y_test,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]}]\n",
    "                    \n",
    "# Apply GridSearchCV to find best parameters for given dataset\n",
    "# verbose is used to describe the steps taken to find best parameters\n",
    "cv = GridSearchCV(SVC(), tuned_parameters, refit = True,verbose= 3) \n",
    "cv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Display parameters selected by GridSearchCV for SVM 3 classes\n",
    "# Parameters obtained: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "print(\"Best parameters to apply are:\",cv.best_params_)\n",
    "# Display model after hyperparameter tuning\n",
    "svm = cv.best_estimator_\n",
    "print(\"Model after tuning is:\\n\",svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the output of model after above parameters are applied to it\n",
    "y_prediction = svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using confusion matrix, classification report and accuracy\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "\n",
    "print(\"Confusion matrix results:\\n\",confusion_matrix(y_prediction,y_test))\n",
    "print(\"\\nClassification report of model:\\n\",classification_report(y_prediction,y_test))\n",
    "print(\"Accuracy score:\",100*accuracy_score(y_prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save SVM model in pickle file\n",
    "pickle.dump(svm,open(f\"{MODEL_NAME}.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read byte from pickle model\n",
    "test_model = pickle.load(open(f\"{MODEL_NAME}.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Testing for a new image\n",
    "def test_img(path):\n",
    "    flat_data = []\n",
    "    img_array = imread(path)\n",
    "    # Resize image\n",
    "    img_resized = resize(img_array,(150,150,3))\n",
    "    flat_data.append(img_resized.flatten())\n",
    "    flat_data = np.array(flat_data)\n",
    "    print(\"Dimensions of original image are:\",img_array.shape)\n",
    "    plt.imshow(img_resized)\n",
    "    y_output = test_model.predict(flat_data)\n",
    "    y_output = features[y_output[0]]\n",
    "    print(\"PREDICTED OUTPUT IS:\",y_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img(\"./test_data/dirty.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img(\"./test_data/clean.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
